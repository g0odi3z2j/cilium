# Networking Model

## Addressing

### IPv6 vs IPv4

Cilium is specifically designed with IPv6 in mind and with native IPv6 as
the long term model to address containers in a scalable fashion. For this
purpose, IPv6 is being treated as the primary citizen and although IPv4
connectivity is entirely supported, its existence is to provide legacy
support.

### Address Allocation

The addressing schema is modeled with the goal to make each cluster node as
independent as possible. The address allocator is thus given a `/112` prefix
out of which it can allocate without any further coordination in the cluster.
This is typically referred to as a host scope allocator.

Each cluster node is identified by a node id (32 bit) which is also embedded
into the container address of each container running on that node. This is
done under the assumption that a container is not migrated by moving it but
by creating a new container instance of the application on another node and
then retiring the old container instance on the original node. This keeps
the amount of state to redistribute to an absolute minimum. Once assigned a
prefix, a node can create and attach containers on its own without any
further orchestration. It also allows to derive the location (node id) of the
container solely based on the destination address of a container.

If IPv4 is to be preferred way for nodes to communicate, the node id can be
derived directly from the IPv4 address of the node, allowing to derive the
IPv4 address via the node IP without any further lookups. In an IPv6 network,
the node id is translated to the IPv6 of the node via a distributed lookup
table.

### Prefix List

```
Cilium universe (cluster prefix):	beef::/64
Container prefix of a node:		beef::NODE_ID:NODE_ID:CONTAINER_ID/112
Node IPv6 address:			beef::NODE_ID:NODE_ID:0/128
					beef::NODE_ID:NODE_ID:ffff/128
```

### NAT46

In order to allow for an IPv4 transition period. Cilium can freely translate
between IPv6 and IPv4 within some restrictions. For this purpose, each
container is assigned an IPv4 address with a host scope (valid only within
the scope of the cluster node). Packets sent to that IPv4 address get
translated to IPv6 and addresses to the IPv6 of the container. The container
is thus reachable via IPv4 without having an actual IPv4 address assigned to
it.

For legacy applications which do not make use of `getaddrinfo()` properly
and thus open an IPv4 socket regardless of the DNS response, a legacy IPv4
address can be assigned. This behaviour needs to be enabled per container
to create an incentive for application developers to move to IPv6.

### DNS46

DNS46 is implemented by various DNS servers including BIND and PowerDNS. It
allows to convert IPv4 `A` responses into IPV6 `AAAA` responses which
represent an IPv4 address. This allows for an IPv6 only container to reach
an IPv4 only endpoint without any changes to the application or container.

## Routing Modes

Cilium routes all packets between nodes. The MAC address of a container is
never exposed outside of the node it runs on. This allows to scale up to
millions of containers. The container itself has no awareness of the
underlying network it runs on, it only contains a default route which
points to the IP address of the node. Given the removal of the routing
cache in the Linux kernel, this reduces the amount of state to keep to the
per connection flow cache (TCP metrics) which allows to terminate millions
of connections in each container.

Once the network packet reaches the BPF program generated by Cilium.
Multiple models can be applied to integrate into existing networking
technology or create new ones. Currently the following modes have been
implemented:

### Direct Routing

This mode leverages the fact that each container is assigned a global IPv6
address which can be routed directly inside the cluster and to external
endpoints. In this direct routing mode, the packet is handed over to the
Linux networking stack and the packet is treated according to the routing
table of the kernel. This allows to integrate with the well proven routing
layer of Linux including support for several kinds of routing daemons.

For the special case of NAT46 or legacy IPv4 only applications, the private
IPv4 source address of the container is translated to the pubic IPv4 address
of the node. Optionally, a pool of public IPv4 addresses can be provided to
allow for entirely stateless address translation on the node.

### UDP Encapsulation (Overlay)

The overlay mode encapsulates all packets for non local containers in a UDP
frame which allows to use either IPv4 or IPv6 on the outer header and can
thus integrate a IPv6 only container network with a traditional IPv4 only
network.

The node ID of a node is automatically derived based on the first global
scope IPv4 address on the node which allows to identify the overlay endpoint
of any container address without requiring to distribute any additional
routes. This again allows to scale unicast traffic to millions of containers.

## Direct server return

FIXME

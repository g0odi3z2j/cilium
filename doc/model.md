# Networking Model

The networking model implemented by Cilium is kept as simple as possible and
has been designed for users of containers to not require knowledge of
networking itself.

Each container receives a unique IPv6 and/or IPv4 address which empowers the
container to initiate connections to any other container or external endpoints
as long as the policy allows it. Complexity caused by integration into
physical or virtual networks is hidden from users.

## Addressing

### Node address

Each node running a cilium agent must be assigned a `/64` IPv6 prefix
allocated from a cluster wide `/48` prefix. Two node addresses are 
utomatically generated based on the assigned prefix by setting the
last 32 bits of the address to `0:0` respectively `0:ffff`.

```
Host address in Linux world: cluster:node:0:ffff
Host address in Cilium world: cluster:node:0:0
```

Optionally, an IPv4 prefix can be specified using the `--ipv4-range` option.
If unspecified, Cilium will generate an IPv4 range based on the template
`10.X.0.0/16` where X will be replaced with the last byte of the first global
IPv4 address configured on the node. The corresponding node address is
`10.X.0.1`.

### Container Addresses

Each container is allocated an IPv6 and an optional IPv4 address (if IPv4 has
been enabled) out of the node address prefix specified.

## IPv6 vs IPv4

Cilium is specifically designed with IPv6 in mind and with native IPv6 as
the long term model to address containers in a scalable fashion. For this
purpose, IPv6 is being treated as the primary citizen and although IPv4
connectivity is entirely supported, its existence is to provide legacy
support.

### NAT46

In order to allow for an IPv4 transition period. Cilium can freely translate
between IPv6 and IPv4 within some restrictions. For this purpose, each
container is assigned an IPv4 address with a host scope (valid only within
the scope of the cluster node). Packets sent to that IPv4 address get
translated to IPv6 and addresses to the IPv6 of the container. The container
is thus reachable via IPv4 without having an actual IPv4 address assigned to
it.

For legacy applications which do not make use of `getaddrinfo()` properly
and thus open an IPv4 socket regardless of the DNS response, a legacy IPv4
address can be assigned. This behaviour needs to be enabled per container
to create an incentive for application developers to move to IPv6.

### DNS46

DNS46 is implemented by various DNS servers including BIND and PowerDNS. It
allows to convert IPv4 `A` responses into IPV6 `AAAA` responses which
represent an IPv4 address. This allows for an IPv6 only container to reach
an IPv4 only endpoint without any changes to the application or container.

## Routing Modes

Cilium routes all packets between nodes. The MAC address of a container is
never exposed outside of the node it runs on. This allows to scale up to
millions of containers. The container itself has no awareness of the
underlying network it runs on, it only contains a default route which
points to the IP address of the node. Given the removal of the routing
cache in the Linux kernel, this reduces the amount of state to keep to the
per connection flow cache (TCP metrics) which allows to terminate millions
of connections in each container.

Once the network packet reaches the BPF program generated by Cilium.
Multiple models can be applied to integrate into existing networking
technology or create new ones. Currently the following modes have been
implemented:

### Direct Routing

This mode leverages the fact that each container is assigned a global IPv6
address which can be routed directly inside the cluster and to external
endpoints. In this direct routing mode, the packet is handed over to the
Linux networking stack and the packet is treated according to the routing
table of the kernel. This allows to integrate with the well proven routing
layer of Linux including support for several kinds of routing daemons.

For the special case of NAT46 or legacy IPv4 only applications, the private
IPv4 source address of the container is translated to the pubic IPv4 address
of the node. Optionally, a pool of public IPv4 addresses can be provided to
allow for entirely stateless address translation on the node.

### UDP Encapsulation (Overlay)

The overlay mode encapsulates all packets for non local containers in a UDP
frame which allows to use either IPv4 or IPv6 on the outer header and can
thus integrate a IPv6 only container network with a traditional IPv4 only
network.

The node ID of a node is automatically derived based on the first global
scope IPv4 address on the node which allows to identify the overlay endpoint
of any container address without requiring to distribute any additional
routes. This again allows to scale unicast traffic to millions of containers.

## Direct server return

TBD
